# -*- coding: utf-8 -*-
"""apple.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tLVMQgBFZN2LHD-BbOrYpIzwPRT91oku
"""

# ðŸš¨ Project: Sentinel Agents â€“ AI Swarm for Autonomous IoT Threat Hunting
# Objective: Use clustering + classification to detect anomalies and malicious traffic in an IoT network

# Step 0: Import Required Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix

# Step 1: Load the Dataset
file_path = "Iot Three hundred.csv"
  # Path to your dataset
df = pd.read_csv(file_path)

# Step 2 (fixed): Preprocess the Data

# Drop obviously useless or textual columns
cols_to_drop = [
    'Source_IP', 'Destination_IP', 'Source_Port', 'Destination_Port', 'Protocol',
    'TCP_Flags', 'Connection_State', 'Device_Manufacturer', 'OS_Version',
    'Firmware_Version', 'Payload_Content_Type', 'Content_Type_File_Transferred',
    'Malware_Type', 'Attack_Vector'
]
df.drop(columns=cols_to_drop, inplace=True, errors='ignore')

# Drop rows with missing values
df.dropna(inplace=True)

# Convert label to integer
df['Label'] = df['Label'].astype(int)

# Handle categorical columns (like 'Traffic_Direction')
from sklearn.preprocessing import LabelEncoder
categorical_cols = df.select_dtypes(include=['object']).columns

for col in categorical_cols:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])

# Convert flags to integers just in case
flag_cols = ['Suspicious_Domain_Query_Flag', 'File_Transfer_Occurred', 'Anomalous_Behavior_Flag', 'External_IP_Accessed_Flag']
for col in flag_cols:
    df[col] = df[col].astype(int)

# Now you're good to go!
X = df.drop(columns=['Label'])
y = df['Label']

# Normalize the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Apply PCA for visualization
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

# Apply KMeans clustering
kmeans = KMeans(n_clusters=2, random_state=42)
kmeans_labels = kmeans.fit_predict(X_scaled)

# Plot clustering result vs true labels
fig, axs = plt.subplots(1, 2, figsize=(14, 6))
sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=kmeans_labels, palette='coolwarm', ax=axs[0])
axs[0].set_title('K-Means Clustering Result (2 Groups)')
axs[0].set_xlabel('PCA Component 1')
axs[0].set_ylabel('PCA Component 2')
axs[0].legend(title='Cluster')

sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=y, palette='Set2', ax=axs[1])
axs[1].set_title('Ground Truth Labels (0 = Benign, 1 = Malicious)')
axs[1].set_xlabel('PCA Component 1')
axs[1].set_ylabel('PCA Component 2')
axs[1].legend(title='True Label')
plt.tight_layout()
plt.show()

# Step 4: Classification - Supervised Learning
# Split data into train/test
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25, random_state=42)

# Train Random Forest classifier
clf = RandomForestClassifier(n_estimators=100, random_state=42)
clf.fit(X_train, y_train)

# Predict
y_pred = clf.predict(X_test)

# Evaluate
print("\nClassification Report:\n", classification_report(y_test, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))

# Plot confusion matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Benign', 'Malicious'], yticklabels=['Benign', 'Malicious'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix - Random Forest Classifier')
plt.show()

# Feature importance plot
importances = clf.feature_importances_
features = X.columns
indices = np.argsort(importances)[-10:]  # top 10 features

plt.figure(figsize=(8, 5))
plt.barh(range(len(indices)), importances[indices], align='center')
plt.yticks(range(len(indices)), [features[i] for i in indices])
plt.xlabel('Importance Score')
plt.title('Top 10 Important Features - Random Forest')
plt.tight_layout()
plt.show()

# Step 5: AI Agent Simulation (Prototype)
class IoTAgent:
    def __init__(self, agent_id, model):
        self.agent_id = agent_id
        self.model = model

    def analyze_traffic(self, sample):
        pred = self.model.predict([sample])
        return "MALICIOUS" if pred[0] == 1 else "BENIGN"

# Create an agent
agent = IoTAgent(agent_id="Device_7_Agent", model=clf)

# Test with a random flow
sample = X_test[5]  # Example test input
result = agent.analyze_traffic(sample)
print(f"Agent Result: {result}")